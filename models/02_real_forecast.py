import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import mean_squared_error, mean_absolute_error
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor
import warnings
warnings.filterwarnings('ignore')

def calculate_smape(actual, forecast):
    """è®¡ç®—å¯¹ç§°å¹³å‡ç»å¯¹ç™¾åˆ†æ¯”è¯¯å·®"""
    return 100/len(actual) * np.sum(2 * np.abs(forecast - actual) / (np.abs(actual) + np.abs(forecast)))

def create_real_features(df):
    """åˆ›å»ºçœŸå®ç‰¹å¾å·¥ç¨‹"""
    print("è¿›è¡ŒçœŸå®ç‰¹å¾å·¥ç¨‹...")
    
    features_df = df.copy()
    
    # æ—¶é—´å‘¨æœŸç‰¹å¾
    features_df['hour_sin'] = np.sin(2 * np.pi * features_df['hour'] / 24)
    features_df['hour_cos'] = np.cos(2 * np.pi * features_df['hour'] / 24)
    features_df['day_sin'] = np.sin(2 * np.pi * features_df['day_of_week'] / 7)
    features_df['day_cos'] = np.cos(2 * np.pi * features_df['day_of_week'] / 7)
    
    # æ›´å¤šæ»åç‰¹å¾
    for lag in [1, 2, 3, 6, 12, 24, 36]:
        features_df[f'lag_{lag}'] = features_df['value'].shift(lag)
    
    # æ›´å¤šæ»šåŠ¨ç‰¹å¾
    for window in [6, 12, 24, 36]:
        features_df[f'rolling_mean_{window}'] = features_df['value'].rolling(window).mean()
        features_df[f'rolling_std_{window}'] = features_df['value'].rolling(window).std()
    
    # å·®åˆ†ç‰¹å¾
    features_df['diff_1'] = features_df['value'].diff(1)
    features_df['diff_12'] = features_df['value'].diff(12)
    
    features_df = features_df.dropna()
    
    return features_df

def train_linear_model(X_train, y_train, X_test, y_test):
    """è®­ç»ƒçº¿æ€§å›å½’æ¨¡å‹"""
    print("è®­ç»ƒçº¿æ€§å›å½’æ¨¡å‹...")
    model = LinearRegression()
    model.fit(X_train, y_train)
    
    # é¢„æµ‹
    y_pred = model.predict(X_test)
    
    # è®¡ç®—æŒ‡æ ‡
    rmse = np.sqrt(mean_squared_error(y_test, y_pred))
    mae = mean_absolute_error(y_test, y_pred)
    smape = calculate_smape(y_test, y_pred)
    
    return model, y_pred, {'RMSE': rmse, 'MAE': mae, 'sMAPE': smape}

def train_random_forest(X_train, y_train, X_test, y_test):
    """è®­ç»ƒéšæœºæ£®æ—æ¨¡å‹"""
    print("è®­ç»ƒéšæœºæ£®æ—æ¨¡å‹...")
    model = RandomForestRegressor(n_estimators=100, random_state=42, max_depth=10)
    model.fit(X_train, y_train)
    
    # é¢„æµ‹
    y_pred = model.predict(X_test)
    
    # è®¡ç®—æŒ‡æ ‡
    rmse = np.sqrt(mean_squared_error(y_test, y_pred))
    mae = mean_absolute_error(y_test, y_pred)
    smape = calculate_smape(y_test, y_pred)
    
    return model, y_pred, {'RMSE': rmse, 'MAE': mae, 'sMAPE': smape}

def create_real_forecasts(df, features_df):
    """åˆ›å»ºçœŸå®é¢„æµ‹"""
    print("å¼€å§‹çœŸå®æ¨¡å‹é¢„æµ‹...")
    
    # é€‰æ‹©ç‰¹å¾åˆ— - ç¡®ä¿ä¸åŒ…å«ç›®æ ‡å˜é‡
    feature_columns = [col for col in features_df.columns if col not in ['value', 'timestamp']]
    
    # å‡†å¤‡æ•°æ®
    X = features_df[feature_columns].values
    y = features_df['value'].values
    
    # åˆ†å‰²æ•°æ® - ç¡®ä¿æœ‰è¶³å¤Ÿçš„æ•°æ®
    split_idx = int(0.8 * len(X))
    X_train, X_test = X[:split_idx], X[split_idx:]
    y_train, y_test = y[:split_idx], y[split_idx:]
    
    print(f"è®­ç»ƒé›†: {X_train.shape}, æµ‹è¯•é›†: {X_test.shape}")
    
    # è®­ç»ƒå¤šä¸ªæ¨¡å‹
    models = {}
    predictions = {}
    metrics = {}
    
    # çº¿æ€§å›å½’
    lr_model, lr_pred, lr_metrics = train_linear_model(X_train, y_train, X_test, y_test)
    models['Linear'] = lr_model
    predictions['Linear'] = lr_pred
    metrics['Linear'] = lr_metrics
    
    # éšæœºæ£®æ—
    rf_model, rf_pred, rf_metrics = train_random_forest(X_train, y_train, X_test, y_test)
    models['RandomForest'] = rf_model
    predictions['RandomForest'] = rf_pred
    metrics['RandomForest'] = rf_metrics
    
    # ç®€å•åŸºå‡†æ¨¡å‹ (å†å²å¹³å‡)
    historical_mean = np.mean(y_train)
    baseline_pred = np.full_like(y_test, historical_mean)
    metrics['Baseline'] = {
        'RMSE': np.sqrt(mean_squared_error(y_test, baseline_pred)),
        'MAE': mean_absolute_error(y_test, baseline_pred),
        'sMAPE': calculate_smape(y_test, baseline_pred)
    }
    
    return models, predictions, metrics, y_test, X_test.shape[0]

def plot_real_results(df, features_df, predictions, metrics, y_test, test_size):
    """ç»˜åˆ¶çœŸå®é¢„æµ‹ç»“æœ"""
    print("ç”ŸæˆçœŸå®é¢„æµ‹å›¾è¡¨...")
    
    fig, axes = plt.subplots(2, 2, figsize=(16, 12))
    fig.suptitle('çœŸå®æ¨¡å‹é¢„æµ‹ç»“æœ - ç½‘æ±›å“¨å…µ', fontsize=16, fontweight='bold')
    
    # 1. é¢„æµ‹ vs å®é™…å¯¹æ¯”
    # è·å–æµ‹è¯•é›†å¯¹åº”çš„æ—¶é—´æˆ³
    split_idx = int(0.8 * len(features_df))
    test_dates = features_df.index[split_idx:split_idx + len(y_test)]
    
    axes[0,0].plot(test_dates, y_test, label='å®é™…æµé‡', color='blue', linewidth=2)
    colors = ['red', 'green']
    model_names = ['Linear', 'RandomForest']
    
    for i, model_name in enumerate(model_names):
        if model_name in predictions:
            pred = predictions[model_name]
            # ç¡®ä¿é¢„æµ‹å€¼å’Œå®é™…å€¼é•¿åº¦ä¸€è‡´
            min_len = min(len(y_test), len(pred))
            axes[0,0].plot(test_dates[:min_len], pred[:min_len], 
                          label=f'{model_name}é¢„æµ‹', color=colors[i], linewidth=1.5, alpha=0.8)
    
    axes[0,0].set_title('æ¨¡å‹é¢„æµ‹ vs å®é™…æµé‡')
    axes[0,0].set_ylabel('æµé‡ (Mbps)')
    axes[0,0].legend()
    axes[0,0].grid(True, alpha=0.3)
    axes[0,0].tick_params(axis='x', rotation=45)
    
    # 2. è¯¯å·®åˆ†å¸ƒ
    errors_data = []
    labels = []
    
    for model_name in model_names:
        if model_name in predictions:
            pred = predictions[model_name]
            min_len = min(len(y_test), len(pred))
            errors = y_test[:min_len] - pred[:min_len]
            errors_data.append(errors)
            labels.append(model_name)
    
    if errors_data:
        axes[0,1].boxplot(errors_data, labels=labels)
        axes[0,1].set_title('é¢„æµ‹è¯¯å·®åˆ†å¸ƒ')
        axes[0,1].set_ylabel('é¢„æµ‹è¯¯å·® (Mbps)')
        axes[0,1].grid(True, alpha=0.3)
    
    # 3. æ€§èƒ½æŒ‡æ ‡å¯¹æ¯”
    model_names = list(metrics.keys())
    rmse_values = [metrics[name]['RMSE'] for name in model_names]
    mae_values = [metrics[name]['MAE'] for name in model_names]
    
    x = np.arange(len(model_names))
    width = 0.35
    
    axes[1,0].bar(x - width/2, rmse_values, width, label='RMSE', alpha=0.8, color='lightblue')
    axes[1,0].bar(x + width/2, mae_values, width, label='MAE', alpha=0.8, color='lightcoral')
    axes[1,0].set_title('æ¨¡å‹æ€§èƒ½æŒ‡æ ‡å¯¹æ¯”')
    axes[1,0].set_xlabel('æ¨¡å‹')
    axes[1,0].set_ylabel('è¯¯å·®å€¼')
    axes[1,0].set_xticks(x)
    axes[1,0].set_xticklabels(model_names)
    axes[1,0].legend()
    axes[1,0].grid(True, alpha=0.3)
    
    # 4. sMAPEå¯¹æ¯”
    smape_values = [metrics[name]['sMAPE'] for name in model_names]
    bars = axes[1,1].bar(model_names, smape_values, alpha=0.8, color=['red', 'green', 'blue'])
    axes[1,1].set_title('sMAPEè¯¯å·®å¯¹æ¯” (%)')
    axes[1,1].set_ylabel('sMAPE (%)')
    axes[1,1].grid(True, alpha=0.3)
    
    # åœ¨æŸ±çŠ¶å›¾ä¸Šæ˜¾ç¤ºæ•°å€¼
    for bar, value in zip(bars, smape_values):
        axes[1,1].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.1,
                      f'{value:.1f}%', ha='center', va='bottom')
    
    plt.tight_layout()
    plt.savefig('real_forecast_results.png', dpi=150, bbox_inches='tight')
    
    return fig

def main():
    print("=== çœŸå®æ¨¡å‹é¢„æµ‹åˆ†æ ===")
    
    # åŠ è½½æ•°æ®
    try:
        df = pd.read_csv('real_traffic_data.csv', index_col='timestamp', parse_dates=True)
        print(f"âœ… åŠ è½½çœŸå®æ•°æ®: {len(df)} æ¡è®°å½•")
    except:
        print("âŒ è¯·å…ˆè¿è¡Œ 01_real_data.py")
        return
    
    # ç‰¹å¾å·¥ç¨‹
    features_df = create_real_features(df)
    print(f"âœ… ç‰¹å¾å·¥ç¨‹å®Œæˆ: {features_df.shape[1]} ä¸ªç‰¹å¾")
    
    # æ¨¡å‹è®­ç»ƒå’Œé¢„æµ‹
    models, predictions, metrics, y_test, test_size = create_real_forecasts(df, features_df)
    
    # æ˜¾ç¤ºç»“æœ
    print(f"\nğŸ“ˆ æ¨¡å‹æ€§èƒ½å¯¹æ¯”:")
    for model_name, model_metrics in metrics.items():
        print(f"{model_name:12} | RMSE: {model_metrics['RMSE']:6.1f} | "
              f"MAE: {model_metrics['MAE']:6.1f} | sMAPE: {model_metrics['sMAPE']:5.1f}%")
    
    # é€‰æ‹©æœ€ä½³æ¨¡å‹
    best_model = min(metrics.items(), key=lambda x: x[1]['sMAPE'])
    print(f"\nğŸ¯ æœ€ä½³æ¨¡å‹: {best_model[0]} (sMAPE: {best_model[1]['sMAPE']:.1f}%)")
    
    # ç”Ÿæˆå›¾è¡¨
    plot_real_results(df, features_df, predictions, metrics, y_test, test_size)
    print("âœ… çœŸå®é¢„æµ‹å›¾è¡¨å·²ä¿å­˜: real_forecast_results.png")
    
    # ä¿å­˜é¢„æµ‹ç»“æœ
    split_idx = int(0.8 * len(features_df))
    test_dates = features_df.index[split_idx:split_idx + len(y_test)]
    
    results_df = pd.DataFrame({
        'timestamp': test_dates,
        'actual': y_test
    })
    
    # æ·»åŠ å„æ¨¡å‹é¢„æµ‹ç»“æœ
    for model_name in ['Linear', 'RandomForest']:
        if model_name in predictions:
            pred = predictions[model_name]
            min_len = min(len(y_test), len(pred))
            results_df[f'{model_name.lower()}_pred'] = np.nan
            results_df.iloc[:min_len, results_df.columns.get_loc(f'{model_name.lower()}_pred')] = pred[:min_len]
    
    results_df.to_csv('real_predictions.csv', index=False)
    print("âœ… é¢„æµ‹ç»“æœå·²ä¿å­˜: real_predictions.csv")
    
    return models, metrics

if __name__ == "__main__":
    trained_models, model_metrics = main()